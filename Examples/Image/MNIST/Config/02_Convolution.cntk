# Parameters can be overwritten on the command line
# for example: cntk configFile=myConfigFile rootDir=../.. 
# For running from Visual Studio add
# currentDirectory=$(SolutionDir)/<path to corresponding data folder> 

command = trainNetwork:testNetwork

precision = "float"; traceLevel = 1 ; deviceId = "auto"

rootDir = ".." ; configDir = "$rootDir$/Config" ; dataDir   = "$rootDir$/Data" ;
outputDir = "$rootDir$/Output" ; modelDir  = "$outputDir$/Models"

modelPath = "$modelDir$/02_Convolution"
stderr = "$outputDir$/02_Convolution_bs_out"

# TRAINING CONFIG
trainNetwork = [
    action = "train"

    BrainScriptNetworkBuilder = {
        imageShape = 28:28:1                        # image dimensions, 1 channel only
        featScale = Constant(1/256)
        labelDim = 10                               # number of distinct labels
        convWScale = 10                             # the initial value scale for the conv layers

        model (features) = {
            featNorm = features.* featScale
            
            c1 = ConvolutionalLayer {16, (5:5), pad = true, initValueScale=convWScale} (featNorm)
			r1 = ReLU(c1)
            p1 = MaxPoolingLayer {(2:2), stride=(2:2)} (r1)
            c2 = ConvolutionalLayer {32, (5:5), pad = true, initValueScale=convWScale} (p1)
			r2 = ReLU(c2)
            p2 = MaxPoolingLayer {(2:2), stride=(2:2)} (r2)
            
            h1 = DenseLayer {128, activation=Sigmoid, init='uniform'} (p2)
            ol = LinearLayer {labelDim, init='uniform'} (h1)
        }.ol

        # inputs
        features = Input {imageShape}
        labels = Input {labelDim}

        # apply model to features
        ol = model (features)

        # loss and error computation
        ce   = CrossEntropyWithSoftmax (labels, ol)
        errs = ClassificationError (labels, ol)

        # declare special nodes
        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (ce)
        evaluationNodes = (errs)
        outputNodes     = (ol)
    }

    SGD = [
        epochSize = 60000
        minibatchSize = 64
        maxEpochs = 15
        learningRatesPerSample = 0.001*5:0.0005
        momentumAsTimeConstant = 0*5:1024
        
        numMBsToShowResult = 500
    ]

    reader = [
        readerType = "CNTKTextFormatReader"
        # See ../REAMDE.md for details on getting the data (Train-28x28_cntk_text.txt).
        file = "$DataDir$/Train-28x28_cntk_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 10
                format = "dense"
            ]
        ]
    ]    
]

# TEST CONFIG
testNetwork = [
    action = test
    minibatchSize = 1024    # reduce this if you run out of memory

    reader = [
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/Test-28x28_cntk_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 10
                format = "dense"
            ]
        ]
    ]
]
